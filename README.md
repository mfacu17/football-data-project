# ‚öΩ Proyecto de An√°lisis de Datos de F√∫tbol con Airflow, PySpark, GCS, BigQuery y PowerBI

## üìù Descripci√≥n

Este proyecto lo inici√© con el objetivo de explorar y poner en pr√°ctica nuevas herramientas del ecosistema de ingenier√≠a de datos. Implementa una arquitectura medall√≥n y un proceso ETL orientado a la transformaci√≥n y an√°lisis de datos de futbol. El objetivo es transformar datos crudos en informaci√≥n √∫til que permita visualizar estad√≠sticas detalladas sobre clubes, jugadores y transferencias.

---
## üõ†Ô∏è Tecnolog√≠as y Herramientas

  - **Apache Airflow**: Orquestaci√≥n de tareas ETL.
  - **PySpark**: Procesamiento distribuido de datos.
  - **Google Cloud Storage (GCS)**: Archivos crudos, almacenamiento intermedio y trazabilidad de errores.
  - **BigQuery**: Almacenamiento y consulta de datos estructurados.
  - **PowerBI**: Visualizaci√≥n de dashboards interactivos.
  - **Conectores BigQuery y GCS para Spark**: Integraci√≥n entre Spark y GCP.
---

## Arquitectura del pipeline

El flujo de datos se divide en tres capas principales:

1. **Raw**:
     - Contiene los archivos CSV crudos almacenados en GCS.
     - Se cargan sin modificaciones en tablas de BigQuery.
2. **Stage**:
     - Contiene los datos curados: sin nulos, duplicados, tipos corregidos e imputaci√≥n de nulos, en algunos casos.
     - Esta limpieza se realiza con PySpark.
3. **Analytics**:
     - Genera m√©tricas y agregaciones relevantes para an√°lisis. 
     - Los scripts de PySpark ejecutan consultas SQL complejas y guardan los resultados directamente en BigQuery.

## Scripts principales

- `etl_raw.py`: Contiene los DAGs correspondientes a la carga de cada una de las tablas en la capa raw de BigQuery.
- `etl_stage.py`: Contiene los DAGs que se ejecutan para realizar las transformaciones necesarias sobre las tablas raw, mediante la importaci√≥n de jobs definidos con PySpark.
- `etl_analytics.py`: Contiene los DAGs necesarios para generar las tablas con m√©tricas y agregaciones en la capa analytics, destinadas a su posterior visualizaci√≥n.

## ‚úÖ Consideraciones
- Se utilizan variables de entorno para manejar credenciales y configuraciones.
- Los datos inv√°lidos (nulos y duplicados) son registrados en GCS para mejorar su trazabilidad.
